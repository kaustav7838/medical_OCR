{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pytesseract opencv-python pandas sqlite3 torch torchvision scikit-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport pytesseract\nfrom pytesseract import Output\nimport os\n\n# Set Tesseract OCR Path\npytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Update based on your system\n\ndef extract_text_from_image(image_path):\n    # Read the image\n    image = cv2.imread(image_path)\n    # Convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # Apply thresholding for better OCR accuracy\n    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n    # Extract text using Tesseract OCR\n    text = pytesseract.image_to_string(thresh, lang='eng')\n    return text\n\n# Process all images in the folder\ndef process_images(folder_path):\n    data = []\n    for file_name in os.listdir(folder_path):\n        if file_name.endswith(('.png', '.jpg', '.jpeg')):\n            file_path = os.path.join(folder_path, file_name)\n            text = extract_text_from_image(file_path)\n            data.append({'file_name': file_name, 'text': text})\n    return data\n\nimage_data = process_images('data/images')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef clean_and_structure_data(raw_data):\n    structured_data = []\n    for record in raw_data:\n        text = record['text']\n        # Example: Split by lines and extract fields (customize for your format)\n        lines = text.split('\\n')\n        record_data = {\n            'patient_name': lines[0] if len(lines) > 0 else None,\n            'age': lines[1].split(':')[1].strip() if len(lines) > 1 and 'Age:' in lines[1] else None,\n            'diagnosis': lines[2] if len(lines) > 2 else None,\n            'prescription': ' '.join(lines[3:]) if len(lines) > 3 else None,\n        }\n        structured_data.append(record_data)\n    return pd.DataFrame(structured_data)\n\nstructured_data = clean_and_structure_data(image_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sqlite3\n\ndef save_to_database(dataframe, db_name, table_name):\n    conn = sqlite3.connect(db_name)\n    dataframe.to_sql(table_name, conn, if_exists='replace', index=False)\n    conn.close()\n\nsave_to_database(structured_data, 'hospital_data.db', 'prescriptions')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data_from_database(db_name, table_name):\n    conn = sqlite3.connect(db_name)\n    dataframe = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n    conn.close()\n    return dataframe\n\nml_data = load_data_from_database('hospital_data.db', 'prescriptions')\n\n# Example ML Pipeline (basic)\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n# Feature extraction from text\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(ml_data['diagnosis'].fillna(''))\ny = ml_data['age'].fillna(0).astype(int)  # Replace age with your target variable\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\naccuracy = model.score(X_test, y_test)\nprint(f\"Model Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Step 4: Optional Enhancements\n\n1. Handwritten Text Improvement:\n\nFine-tune a CRNN or use pre-trained models like IAM Dataset CRNN.\n\n\n\n2. Data Visualization:\n\nUse Matplotlib or Seaborn to visualize trends in data.\n\n\n\n3. Validation:\n\nValidate OCR output manually for higher accuracy before ML processing.\n\n\n\n4. Deployment:\n\nPackage the project as a desktop application using PyInstaller or Tkinter for a GUI.\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}